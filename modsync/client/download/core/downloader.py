"""
Core downloader functionality for ModSync client
"""

import os
import time
import threading
from queue import Queue, Empty
from modsync.client.network.connection.connection_utils import VDS_SERVER_IP
from modsync.client.network.connection.retry_utils import ConnectionManager


class Downloader:
    """Core download functionality"""
    
    @staticmethod
    def _download_file_with_retry(url, local_path, file_info, chunk_size=32768, timeout=30, strategy_settings=None):
        """–ó–∞–≥—Ä—É–∑–∫–∞ —Ñ–∞–π–ª–∞ —Å –ø–æ–≤—Ç–æ—Ä–Ω—ã–º–∏ –ø–æ–ø—ã—Ç–∫–∞–º–∏ –ø—Ä–∏ –æ—à–∏–±–∫–∞—Ö —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è"""
        if strategy_settings is None:
            strategy_settings = {}
        
        dir_path = os.path.dirname(local_path)
        if not os.path.exists(dir_path):
            os.makedirs(dir_path)
        
        max_retries = strategy_settings.get('retry_count', 5)
        base_delay = strategy_settings.get('retry_delay', 1)
        
        for attempt in range(max_retries + 1):
            try:
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–µ –ø–µ—Ä–µ–¥ –∑–∞–≥—Ä—É–∑–∫–æ–π
                if attempt > 0 and not ConnectionManager.is_server_available(timeout=2):
                    raise ConnectionError("–°–µ—Ä–≤–µ—Ä –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω")
                
                response = ConnectionManager.make_request_with_retry(
                    url, timeout=timeout, stream=True
                )
                response.raise_for_status()
                
                total_size = int(response.headers.get('content-length', 0))
                downloaded = 0
                
                with open(local_path, 'wb') as f:
                    for chunk in response.iter_content(chunk_size=chunk_size):
                        if chunk:
                            f.write(chunk)
                            downloaded += len(chunk)
                
                # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ü–µ–ª–æ—Å—Ç–Ω–æ—Å—Ç–∏
                if total_size > 0 and os.path.getsize(local_path) != total_size:
                    os.remove(local_path)
                    raise Exception(f"–ù–µ—Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ —Ä–∞–∑–º–µ—Ä–∞: –æ–∂–∏–¥–∞–µ–º—ã–π {total_size}, –ø–æ–ª—É—á–µ–Ω {os.path.getsize(local_path)}")
                
                return True
                
            except Exception as e:
                if attempt < max_retries:
                    delay = base_delay * (attempt + 1)
                    print(f"[STRATEGY] ‚è≥ –ü–æ–ø—ã—Ç–∫–∞ {attempt + 1}/{max_retries} –¥–ª—è {file_info['relpath']} –Ω–µ —É–¥–∞–ª–∞—Å—å, –ø–æ–≤—Ç–æ—Ä —á–µ—Ä–µ–∑ {delay:.1f}—Å: {str(e)}")
                    time.sleep(delay)
                    continue
                else:
                    if os.path.exists(local_path):
                        os.remove(local_path)
                    raise
        
        return False
    
    @staticmethod
    def _download_with_resume(url, local_path, file_info, chunk_size=131072, retry_count=3, timeout=60, strategy_settings=None):
        """–ó–∞–≥—Ä—É–∑–∫–∞ —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π –≤–æ–∑–æ–±–Ω–æ–≤–ª–µ–Ω–∏—è –¥–ª—è –±–æ–ª—å—à–∏—Ö —Ñ–∞–π–ª–æ–≤"""
        if strategy_settings is None:
            strategy_settings = {}
        
        file_size = file_info.get('size', 0)
        mode = 'wb'
        downloaded_size = 0
        headers = {}

        # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å—É—â–µ—Å—Ç–≤—É—é—â–µ–≥–æ —Ñ–∞–π–ª–∞ –¥–ª—è –≤–æ–∑–æ–±–Ω–æ–≤–ª–µ–Ω–∏—è
        if os.path.exists(local_path):
            downloaded_size = os.path.getsize(local_path)
            if 0 < downloaded_size < file_size:
                mode = 'ab'
                headers = {'Range': f'bytes={downloaded_size}-'}
            else:
                downloaded_size = 0
                mode = 'wb'
                headers = {}

        for attempt in range(retry_count + 1):
            try:
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–µ
                if attempt > 0 and not ConnectionManager.is_server_available(timeout=3):
                    raise ConnectionError("–°–µ—Ä–≤–µ—Ä –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω")
                
                response = ConnectionManager.make_request_with_retry(
                    url, timeout=timeout, stream=True, headers=headers
                )

                # –û–±—Ä–∞–±–æ—Ç–∫–∞ —á–∞—Å—Ç–∏—á–Ω–æ–≥–æ –∫–æ–Ω—Ç–µ–Ω—Ç–∞
                if mode == 'ab' and response.status_code == 206:
                    print(f"[STRATEGY] üîÑ –í–æ–∑–æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ –∑–∞–≥—Ä—É–∑–∫–∏ {file_info['relpath']} —Å {downloaded_size/1024/1024:.1f}MB")
                elif mode == 'ab':
                    print(f"[STRATEGY] ‚ö†Ô∏è –°–µ—Ä–≤–µ—Ä –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç –≤–æ–∑–æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ, –Ω–∞—á–∏–Ω–∞–µ–º –∑–∞–Ω–æ–≤–æ: {file_info['relpath']}")
                    mode = 'wb'
                    downloaded_size = 0
                    headers = {}
                    response = ConnectionManager.make_request_with_retry(
                        url, timeout=timeout, stream=True
                    )

                total_size = file_size
                start_time = time.time()

                with open(local_path, mode) as f:
                    for chunk in response.iter_content(chunk_size=chunk_size):
                        if chunk:
                            f.write(chunk)
                            downloaded_size += len(chunk)

                # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ü–µ–ª–æ—Å—Ç–Ω–æ—Å—Ç–∏
                final_size = os.path.getsize(local_path)
                if final_size == file_size:
                    elapsed = time.time() - start_time
                    avg_speed = file_size / elapsed / 1024 / 1024 if elapsed > 0 else 0
                    print(f"[STRATEGY] ‚úÖ {file_info['relpath']} —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω! ({elapsed:.1f}—Å, {avg_speed:.1f} MB/s)")
                    return True
                else:
                    print(f"[ERROR] ‚ùå –ù–µ—Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ —Ä–∞–∑–º–µ—Ä–∞ —Ñ–∞–π–ª–∞ {file_info['relpath']}: –æ–∂–∏–¥–∞–µ–º—ã–π {file_size}, –ø–æ–ª—É—á–µ–Ω {final_size}")
                    if os.path.exists(local_path):
                        os.remove(local_path)
                    return False

            except Exception as e:
                print(f"[ERROR] ‚ùå –ü–æ–ø—ã—Ç–∫–∞ {attempt + 1}/{retry_count + 1} –Ω–µ —É–¥–∞–ª–∞—Å—å –¥–ª—è {file_info['relpath']}: {str(e)}")
                if attempt < retry_count:
                    time.sleep(2 ** attempt)  # –≠–∫—Å–ø–æ–Ω–µ–Ω—Ü–∏–∞–ª—å–Ω–∞—è –∑–∞–¥–µ—Ä–∂–∫–∞
                else:
                    if os.path.exists(local_path):
                        os.remove(local_path)
                    return False

        return False
    
    @staticmethod
    def _download_parallel(files, max_workers=4, chunk_size=32768, timeout=30, strategy_settings=None):
        """–ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω–∞—è –∑–∞–≥—Ä—É–∑–∫–∞ —Ñ–∞–π–ª–æ–≤ —Å –∞–≤—Ç–æ–ø–µ—Ä–µ–ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ–º"""
        if strategy_settings is None:
            strategy_settings = {}
        
        results = {}
        queue = Queue()

        for file_info in files:
            queue.put(file_info)

        def worker():
            while not queue.empty():
                try:
                    file_info = queue.get_nowait()
                    url = f"{VDS_SERVER_IP}/{file_info['relpath']}"
                    success = Downloader._download_file_with_retry(
                        url, file_info['local_path'], file_info, chunk_size, timeout, strategy_settings
                    )
                    results[file_info['relpath']] = success

                    queue.task_done()
                except Empty:
                    break
                except Exception as e:
                    print(f"[ERROR] –û—à–∏–±–∫–∞ –≤ –ø–æ—Ç–æ–∫–µ –∑–∞–≥—Ä—É–∑–∫–∏: {str(e)}")
                    queue.task_done()

        # –ó–∞–ø—É—Å–∫ –ø–æ—Ç–æ–∫–æ–≤
        threads = []
        actual_workers = min(max_workers, len(files), 20)  # –ú–∞–∫—Å–∏–º—É–º 20 –ø–æ—Ç–æ–∫–æ–≤

        for _ in range(actual_workers):
            t = threading.Thread(target=worker, daemon=True)
            t.start()
            threads.append(t)

        # –û–∂–∏–¥–∞–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è
        for t in threads:
            t.join()

        queue.join()

        return results