"""
Adaptive download strategy implementation
"""

import time
from modsync.client.download.strategies.base_strategy import BaseDownloadStrategy
from modsync.client.download.core.downloader import Downloader


class AdaptiveStrategy(BaseDownloadStrategy):
    """Adaptive download strategy - classifies files by size and applies different techniques"""
    
    def execute_download(self, files_to_download, file_distribution=None):
        """Execute adaptive download"""
        settings = self.config['settings']
        
        # Classify files by size
        tiny_files = [f for f in files_to_download if f.get('size', 0) < 100 * 1024]  # <100KB
        small_files = [f for f in files_to_download if 100 * 1024 <= f.get('size', 0) < 1 * 1024 * 1024]  # 100KB-1MB
        medium_files = [f for f in files_to_download if 1 * 1024 * 1024 <= f.get('size', 0) < 10 * 1024 * 1024]  # 1-10MB
        huge_files = [f for f in files_to_download if f.get('size', 0) >= 10 * 1024 * 1024]  # >10MB
        
        results = {}
        total_files = len(files_to_download)
        processed = 0
        
        # Download tiny files (maximum parallelism)
        if tiny_files:
            self._log_info(f"‚ö° –ó–∞–≥—Ä—É–∑–∫–∞ {len(tiny_files)} –º–µ–ª–∫–∏—Ö —Ñ–∞–π–ª–æ–≤ (<100KB) —Å {settings.get('tiny_file_workers', 8)} –ø–æ—Ç–æ–∫–∞–º–∏")
            tiny_results = Downloader._download_parallel(
                tiny_files,
                max_workers=settings.get('tiny_file_workers', 8),
                chunk_size=settings.get('chunk_size', 32768),
                timeout=settings.get('timeout', 30),
                strategy_settings=settings
            )
            results.update(tiny_results)
            processed += len(tiny_files)
            
            if self.progress_callback:
                self.progress_callback(None, processed / total_files * 100, processed, total_files)
        
        # Download small files
        if small_files:
            self._log_info(f"üöÄ –ó–∞–≥—Ä—É–∑–∫–∞ {len(small_files)} —Ñ–∞–π–ª–æ–≤ (100KB-1MB) —Å {settings.get('small_file_workers', 4)} –ø–æ—Ç–æ–∫–∞–º–∏")
            small_results = Downloader._download_parallel(
                small_files,
                max_workers=settings.get('small_file_workers', 4),
                chunk_size=settings.get('chunk_size', 32768),
                timeout=settings.get('timeout', 30),
                strategy_settings=settings
            )
            results.update(small_results)
            processed += len(small_files)
            
            if self.progress_callback:
                self.progress_callback(None, processed / total_files * 100, processed, total_files)
        
        # Download medium files
        if medium_files:
            self._log_info(f"üü° –ó–∞–≥—Ä—É–∑–∫–∞ {len(medium_files)} —Ñ–∞–π–ª–æ–≤ (1-10MB) —Å {settings.get('medium_file_workers', 2)} –ø–æ—Ç–æ–∫–∞–º–∏")
            medium_results = Downloader._download_parallel(
                medium_files,
                max_workers=settings.get('medium_file_workers', 2),
                chunk_size=settings.get('chunk_size', 65536),
                timeout=settings.get('timeout', 45),
                strategy_settings=settings
            )
            results.update(medium_results)
            processed += len(medium_files)
            
            if self.progress_callback:
                self.progress_callback(None, processed / total_files * 100, processed, total_files)
        
        # Download huge files (sequentially with resume support)
        if huge_files:
            self._log_info(f"üî¥ –ó–∞–≥—Ä—É–∑–∫–∞ {len(huge_files)} –ì–ò–ì–ê–ù–¢–°–ö–ò–• —Ñ–∞–π–ª–æ–≤ (>10MB) —Å –≤–æ–∑–æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ–º")
            for file_info in huge_files:
                processed += 1
                
                if self.progress_callback:
                    self.progress_callback(None, processed / total_files * 100, processed, total_files)
                
                url = f"http://147.45.184.36:8000/{file_info['relpath']}"
                success = Downloader._download_with_resume(
                    url,
                    file_info['local_path'],
                    file_info,
                    chunk_size=settings.get('chunk_size', 131072),
                    retry_count=settings.get('retry_count', 5),
                    timeout=settings.get('timeout', 60),
                    strategy_settings=settings
                )
                results[file_info['relpath']] = success
        
        return {'success': True, 'results': results}